{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First find the article ID for the Harry Potter page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r = requests.get('http://harrypotter.wikia.com/api/v1/Articles/Top')\n",
    "hp_id = [it['id'] for it in json.loads(r.content)['items'] if it['title'] == 'Harry Potter'][0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the content of the page as a JSON file and dump it to file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r = requests.get('http://harrypotter.wikia.com/api/v1/Articles/AsSimpleJson', params={'id': hp_id})\n",
    "json.dump(r.text, open('HarryPotterWikia1.json', 'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pulling out the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cont = json.loads(r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('HarryPotterWikia.txt', 'w') as f:\n",
    "    for section in cont['sections']:\n",
    "        #print(section['title'])\n",
    "        #f.write(section['title'].encode('utf8')+'\\n')\n",
    "        f.write(section['title']+'\\n')\n",
    "        for unit in section['content']:\n",
    "            if unit['type'] == 'paragraph':\n",
    "                f.write(unit['text']+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playing with NLP on the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import textacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from itertools import tee\n",
    "\n",
    "def make_list(generator):\n",
    "    entries = []\n",
    "    for a in generator:\n",
    "        entries.append(a)\n",
    "    return entries\n",
    "\n",
    "def semi_structured(doc):\n",
    "    statements = textacy.extract.semistructured_statements(doc, 'Harry', cue='be')\n",
    "    for i, s in enumerate(statements):\n",
    "        #if i < 10:\n",
    "            the_rest = textacy.Doc(s[2].text, lang='en')\n",
    "            names = make_list(textacy.extract.named_entities(the_rest))\n",
    "            nouns = textacy.extract.noun_chunks(the_rest)\n",
    "            #triplets = textacy.extract.subject_verb_object_triples(the_rest)\n",
    "            ngram = make_list(textacy.extract.ngrams(the_rest,5))\n",
    "            #print(is_n_empty(names),\" \",is_n_empty(ngram) )    \n",
    "\n",
    "            if len(names)*len(ngram)> 0:\n",
    "                print(\" -- My sentence\")\n",
    "                print(s)\n",
    "                print(\" --- Other names\")\n",
    "                for i_name in names:\n",
    "                    print(i_name)\n",
    "            #print(\" --- Nouns\")\n",
    "            #for i_noun in nouns:\n",
    "            #    print(i_noun)\n",
    "                print(\" --- ngram\")\n",
    "                for i_gram in ngram:\n",
    "                    print(i_gram)\n",
    "        #sents_parsed = dependency_parser.parse_sents(sentences=s[2].text)        \n",
    "#        print(sents_parsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "def extract_pattern(doc):\n",
    "    statements = textacy.extract.semistructured_statements(doc, 'Harry', cue='be')\n",
    "    for i, s in enumerate(statements):\n",
    "        if i < 20:\n",
    "\n",
    "            to_tokenize = s[0].text+\" \"+s[1].text+\" \"+s[2].text\n",
    "            the_rest = textacy.Doc(to_tokenize, lang='en')  \n",
    "            main_verbs = textacy.spacy_utils.get_main_verbs_of_sent(the_rest)\n",
    "            for verb in main_verbs:\n",
    "                span = textacy.spacy_utils.get_span_for_verb_auxiliaries(verb)\n",
    "                sub_list = []\n",
    "                ob_list = []\n",
    "                complex_verb = the_rest[span[0]].text\n",
    "                for a in range(span[0]+1,span[1]+1):\n",
    "                    complex_verb +=\" \"+the_rest[span[1]].text\n",
    "                ##### -----\n",
    "                subjects = textacy.spacy_utils.get_subjects_of_verb(verb)\n",
    "                objects = textacy.spacy_utils.get_objects_of_verb(verb)\n",
    "                if len(subjects) >0 and len(objects) > 0:\n",
    "                    print(\" -- My sentence\")\n",
    "                    print(s)\n",
    "                    print(subjects,complex_verb,objects)\n",
    "                \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -- My sentence\n",
      "(Harry, was, under increasing pressure to show that he was not just a famous name)\n",
      "1\n",
      "[he] was not [name]\n",
      " -- My sentence\n",
      "(Harry, was, to be replaced amusing, and so reverted to teasing Harry about having to stay at Hogwarts for the holidays)\n",
      "1\n",
      "[Harry] was [replaced, reverted]\n",
      " -- My sentence\n",
      "(Harry, was, Slytherin's heir)\n",
      "1\n",
      "[Harry] was [heir]\n",
      " -- My sentence\n",
      "(Harry, were, furious with Hermione and they stopped speaking to her)\n",
      "1\n",
      "[they] stopped [speaking]\n",
      " -- My sentence\n",
      "(Harry, was, sceptical until Black and Lupin forced Pettigrew back into his human form)\n",
      "2\n",
      "[Black, Lupin] forced [Pettigrew]\n",
      " -- My sentence\n",
      "(Harry, was, not particularly concerned about and something he did not inform anyone of)\n",
      "1\n",
      "[he] did inform inform [anyone]\n",
      " -- My sentence\n",
      "(Harry, was, free of the spell that petrified him)\n",
      "1\n",
      "[that] petrified [him]\n",
      " -- My sentence\n",
      "(Harry, was, still completely grief-stricken over the death of his beloved owl)\n",
      "1\n",
      "[Harry] was [grief]\n",
      " -- My sentence\n",
      "(Harry, were, the only students mentioned by name in the will)\n",
      "1\n",
      "[Harry] were [students]\n"
     ]
    }
   ],
   "source": [
    "text = textacy.preprocess.transliterate_unicode(open('HarryPotterWikia.txt').read())\n",
    "doc = textacy.Doc(text, lang='en')\n",
    "#semi_structured(doc)\n",
    "extract_pattern(doc)\n",
    "#print(doc[1])\n",
    "#triple(doc)\n",
    "#statements = textacy.extract.semistructured_statements(doc, 'Harry')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sents_parsed' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-f47c77514172>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msents_parseobjs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msents_parsed\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msent\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msents_parseobjs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sents_parsed' is not defined"
     ]
    }
   ],
   "source": [
    "#sents_parseobjs = [obj for sent in sents_parsed for obj in sent]\n",
    "#sents_parseobjs[0].tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sovs = textacy.extract.subject_verb_object_triples(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i, sov in enumerate(sovs):\n",
    "    if i < 20:\n",
    "        print(sov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "textacy.keyterms.key_terms_from_semantic_network(doc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
